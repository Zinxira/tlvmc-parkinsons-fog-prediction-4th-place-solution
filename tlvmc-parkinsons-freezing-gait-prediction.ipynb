{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parkinson's Freezing of Gait Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Additional useful references:\n",
    "* Competition homepage: https://www.kaggle.com/competitions/tlvmc-parkinsons-freezing-gait-prediction/overview\n",
    "* Google Brain Ventilator Pressure Prediction Winning team's solution https://www.kaggle.com/competitions/ventilator-pressure-prediction/discussion/285965\n",
    "* Feature selection (not used in this notebook but was used for other prototypes): https://www.kaggle.com/code/averkovanika/parkinson-s-fog-mi-based-feature-selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading the libraries + global variables:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import datetime\n",
    "import glob\n",
    "import json\n",
    "import multiprocessing\n",
    "import os\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from models import MultiResidualBiGRU\n",
    "from preprocessing import (\n",
    "    SeqFoGDataset,\n",
    "    add_noactivity_lbls,\n",
    "    convert_g_to_ms2,\n",
    "    preprocess_defog,\n",
    "    preprocess_tdcsfog,\n",
    ")\n",
    "from pytorch_ranger import Ranger\n",
    "from scipy.interpolate import interp1d\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from torch import nn, optim\n",
    "from torch.cuda.amp import autocast\n",
    "from torch.optim import lr_scheduler\n",
    "from torch.utils.data import DataLoader, SubsetRandomSampler\n",
    "from tqdm.notebook import tqdm\n",
    "from training import get_model_id, train\n",
    "from util import set_seed\n",
    "\n",
    "RND_SEED = 0\n",
    "GPU_ID = 0\n",
    "USE_GPU = True\n",
    "\n",
    "if torch.cuda.is_available() and USE_GPU:\n",
    "    gpu_name = torch.cuda.get_device_name(GPU_ID)\n",
    "    print(f\"Using GPU {GPU_ID} - {gpu_name}\")\n",
    "    device = torch.device(f\"cuda:{GPU_ID}\")\n",
    "else:\n",
    "    print(f\"CUDA is not available. Using CPU\")\n",
    "    device = torch.device(\"cpu\")\n",
    "\n",
    "N_CPU_CORES = multiprocessing.cpu_count()\n",
    "\n",
    "BASE_FOLDER = os.path.join(\"input\")\n",
    "\n",
    "print(f\"Number of CPU cores available: {N_CPU_CORES}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the following piece of code, the parameters correspond to the ones used to obtain the model that achieved the best private score on the Kaggle leaderboard. To train the simplified version of the model detailed in the model summary, just change the \"NL\" parameter to 1. \n",
    "\n",
    "Note: a UserWarning related to the Ranger optimizer should appear during the training, it can be ignored. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_seed(RND_SEED)\n",
    "\n",
    "PARAMS = {\n",
    "    \"SEED\": RND_SEED,  # random seed, for reproducibility\n",
    "    \"DSPART\": 1.0,  # eg 0.5 = only consider 50% of the full dataset\n",
    "    \"TRAINPART\": 0.8,  # eg 0.8 means 80% = training set / 20% = validation set\n",
    "    \"DOWNHZ\": 50,  # by default (None), defog 100Hz sequences are upsampled to\n",
    "    # 128Hz. Else this value indicates the frequency at which all the sequences\n",
    "    # are downsampled (in Hz)\n",
    "    \"MAXSEQLEN\": 200000,  # maximum sequence length ; None if no limit.\n",
    "    \"MAXCHUNKSIZE\": 500000,  # given the important size of some sequences, we\n",
    "    # give the ability to process them in chunks, and this is the maximum size\n",
    "    # for 1 chunk\n",
    "    \"BS\": 1,  # batch size\n",
    "    \"NWORK\": 0,  # number of workers used in dataloaders\n",
    "    \"ISIZE\": 3,  # GRU's input size\n",
    "    \"HSIZE\": 128,  # GRU's hidden size\n",
    "    \"NL\": 3,  # number of layers\n",
    "    \"NC\": 4,  # number of classes\n",
    "    \"NEPOCHS\": 20,  # number of epochs\n",
    "    \"LR\": 1e-3,  # learning rate\n",
    "    # \"WDECAY\": 1e-2,  # weight decay\n",
    "    # \"PATIENCE\": 3,  # patience in epochs before the lr is modified\n",
    "    # \"FACTOR\": 0.5,  # factor by which the lr is multiplied when decreased\n",
    "    \"COSSTART\": 0.75,  # determines at what % of the epochs the cosine annealing\n",
    "    # starts\n",
    "    \"VINTER\": 1,  # validation interval in epochs (1 = validation at each epoch)\n",
    "}\n",
    "\n",
    "# defining the model, optimizer and criterion\n",
    "model = MultiResidualBiGRU(\n",
    "    PARAMS[\"ISIZE\"],\n",
    "    PARAMS[\"HSIZE\"],\n",
    "    PARAMS[\"NC\"],\n",
    "    PARAMS[\"NL\"],\n",
    ")\n",
    "model = model.to(device)\n",
    "\n",
    "MODELS_FOLDER = \"models\"\n",
    "model_id = get_model_id(model, extra_info=\"\")\n",
    "model_path = os.path.join(MODELS_FOLDER, model_id)\n",
    "params_path = os.path.join(model_path, \"params.json\")\n",
    "if not os.path.isdir(model_path):\n",
    "    os.makedirs(model_path)\n",
    "with open(params_path, \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(PARAMS, f, ensure_ascii=False, indent=4)\n",
    "\n",
    "# loading and preprocessing data\n",
    "defog_TRAIN_PATH = os.path.join(BASE_FOLDER, \"train\", \"defog\")\n",
    "tDCS_TRAIN_PATH = os.path.join(BASE_FOLDER, \"train\", \"tdcsfog\")\n",
    "train_ds = SeqFoGDataset(\n",
    "    defog_TRAIN_PATH,\n",
    "    tDCS_TRAIN_PATH,\n",
    "    ds_part=PARAMS[\"DSPART\"],\n",
    "    max_seq_len=PARAMS[\"MAXSEQLEN\"],\n",
    "    down_hz=PARAMS[\"DOWNHZ\"],\n",
    ")\n",
    "\n",
    "# creating training and validation samplers for the associated dataloaders\n",
    "train_size = int(PARAMS[\"TRAINPART\"] * len(train_ds))\n",
    "valid_size = len(train_ds) - train_size\n",
    "indices = torch.randperm(len(train_ds))\n",
    "train_sampler = SubsetRandomSampler(indices[:train_size])\n",
    "valid_sampler = SubsetRandomSampler(\n",
    "    indices[train_size : train_size + valid_size]\n",
    ")\n",
    "\n",
    "# training and validation dataloaders\n",
    "train_loader = DataLoader(\n",
    "    train_ds,\n",
    "    batch_size=PARAMS[\"BS\"],\n",
    "    sampler=train_sampler,\n",
    "    pin_memory=True,\n",
    "    num_workers=PARAMS[\"NWORK\"],\n",
    ")\n",
    "valid_loader = DataLoader(\n",
    "    train_ds,\n",
    "    batch_size=PARAMS[\"BS\"],\n",
    "    sampler=valid_sampler,\n",
    "    pin_memory=True,\n",
    "    num_workers=PARAMS[\"NWORK\"],\n",
    ")\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "opt = Ranger(model.parameters(), lr=PARAMS[\"LR\"])\n",
    "\n",
    "cos_epoch = int(PARAMS[\"NEPOCHS\"] * PARAMS[\"COSSTART\"])\n",
    "T_max = (PARAMS[\"NEPOCHS\"] - cos_epoch) * len(train_loader)\n",
    "scheduler = lr_scheduler.CosineAnnealingLR(opt, T_max)\n",
    "\n",
    "print(model)\n",
    "\n",
    "# training loop\n",
    "history = train(\n",
    "    train_loader,\n",
    "    valid_loader,\n",
    "    model,\n",
    "    PARAMS[\"MAXCHUNKSIZE\"],\n",
    "    PARAMS[\"NEPOCHS\"],\n",
    "    PARAMS[\"VINTER\"],\n",
    "    criterion,\n",
    "    opt,\n",
    "    scheduler,\n",
    "    cos_epoch,\n",
    "    device,\n",
    "    model_path,\n",
    "    verbose=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading a model & Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# some auxiliary functions\n",
    "def read_seq(fpath):\n",
    "    seq_id = fpath.split(os.path.sep)[-1].split(\".\")[0]\n",
    "    seq = pd.read_csv(fpath)\n",
    "    return seq_id, seq\n",
    "\n",
    "\n",
    "def resample_seq_df(df, in_hz, out_hz, with_classes=True, with_bool_cols=True):\n",
    "    in_ms = (1 / in_hz) * 1000\n",
    "    out_ms = (1 / out_hz) * 1000\n",
    "    FLOAT_COLS = [\"AccV\", \"AccML\", \"AccAP\"]\n",
    "    if with_classes:\n",
    "        CLASSES_COLS = [\"StartHesitation\", \"Turn\", \"Walking\"]\n",
    "    if with_bool_cols:\n",
    "        BOOL_COLS = [\"Valid\", \"Task\"]\n",
    "\n",
    "    df[\"Time\"] = pd.to_timedelta(df[\"Time\"] * in_ms, unit=\"ms\")\n",
    "    df = df.set_index(\"Time\")\n",
    "\n",
    "    resampled_df = (\n",
    "        df[FLOAT_COLS]\n",
    "        .resample(f\"{out_ms}ms\")\n",
    "        .mean()  # new val = \"mean\" in the 7.8125ms interval\n",
    "        .interpolate()  # sometimes there is no previous value in the 7.8125ms\n",
    "        # interval: we interpolate (linearly by default)\n",
    "    )\n",
    "\n",
    "    cols = []\n",
    "    if with_classes:\n",
    "        cols = cols + CLASSES_COLS\n",
    "    if with_bool_cols:\n",
    "        cols = cols + BOOL_COLS\n",
    "    if cols != []:\n",
    "        resampled_df[cols] = (\n",
    "            df[cols]\n",
    "            .resample(f\"{out_ms}ms\")\n",
    "            .first()\n",
    "            .ffill()  # new val = previous val\n",
    "        )\n",
    "\n",
    "    # needed as the introduction of NaNs forced pd to make all cols float\n",
    "    if with_classes:\n",
    "        resampled_df[CLASSES_COLS] = resampled_df[CLASSES_COLS].astype(int)\n",
    "    if with_bool_cols:\n",
    "        resampled_df[BOOL_COLS] = resampled_df[BOOL_COLS].astype(bool)\n",
    "\n",
    "    return resampled_df\n",
    "\n",
    "\n",
    "def convert_g_to_ms2(df):\n",
    "    # 1g = 9.80665m/s^2\n",
    "    df[\"AccV\"] = df[\"AccV\"] * 9.80665\n",
    "    df[\"AccML\"] = df[\"AccML\"] * 9.80665\n",
    "    df[\"AccAP\"] = df[\"AccAP\"] * 9.80665\n",
    "    return df\n",
    "\n",
    "\n",
    "def normalize(seq_features):\n",
    "    return StandardScaler().fit_transform(seq_features)\n",
    "\n",
    "\n",
    "def preprocess_tdcs_seq(seq_df, device, down_hz=None):\n",
    "    FEATURES = [\"AccV\", \"AccML\", \"AccAP\"]\n",
    "\n",
    "    if down_hz is not None:\n",
    "        # downsample the data from 128Hz to ??Hz\n",
    "        seq_df = resample_seq_df(\n",
    "            seq_df, 128, down_hz, with_classes=False, with_bool_cols=False\n",
    "        )\n",
    "\n",
    "    # extracting the features columns and normalizing them\n",
    "    seq = seq_df[FEATURES].values\n",
    "    seq = normalize(seq)\n",
    "    seq = torch.from_numpy(seq).float().to(device)\n",
    "    seq = seq.unsqueeze(0)  # adding batch dim\n",
    "    return seq\n",
    "\n",
    "\n",
    "def preprocess_defog_seq(seq_df, device, down_hz=None):\n",
    "    if down_hz is None:\n",
    "        # upsampling the data from 100Hz to 128Hz\n",
    "        # seq = upsample_defog(seq)\n",
    "        seq_df = resample_seq_df(\n",
    "            seq_df, 100, 128, with_classes=False, with_bool_cols=False\n",
    "        )\n",
    "    else:\n",
    "        # downsample the data from 100Hz to ??Hz\n",
    "        seq_df = resample_seq_df(\n",
    "            seq_df, 100, down_hz, with_classes=False, with_bool_cols=False\n",
    "        )\n",
    "\n",
    "    # upsampling the data from 100Hz to 128Hz\n",
    "    # seq_df = upsample_defog(seq_df, with_categorical_cols=False)\n",
    "\n",
    "    # defog data is in g: we convert it into m/s^2\n",
    "    seq_df = convert_g_to_ms2(seq_df)\n",
    "\n",
    "    return preprocess_tdcs_seq(seq_df, device)\n",
    "\n",
    "\n",
    "def predict_lbls_df(model, seq, seq_id):\n",
    "    #     with autocast():  # mixed precision\n",
    "    pred, h = model(seq)\n",
    "    pred = torch.nn.functional.softmax(pred[0], dim=1)\n",
    "    pred = pred.cpu().numpy()[:, :3]\n",
    "    return pred\n",
    "\n",
    "\n",
    "def resample_seq(seq_inhz, in_hz, out_hz):\n",
    "    out_size = int(seq_inhz.shape[0] * (out_hz / in_hz))\n",
    "    time_inhz = np.linspace(0, 1, seq_inhz.shape[0])\n",
    "    time_outhz = np.linspace(0, 1, out_size)\n",
    "\n",
    "    seq_outhz = np.zeros((out_size, seq_inhz.shape[1]))\n",
    "\n",
    "    for i in range(seq_inhz.shape[1]):\n",
    "        interp_func = interp1d(time_inhz, seq_inhz[:, i])\n",
    "        seq_outhz[:, i] = interp_func(time_outhz)\n",
    "\n",
    "    return seq_outhz\n",
    "\n",
    "\n",
    "def build_res_df(preds):\n",
    "    CLASSES = [\"StartHesitation\", \"Turn\", \"Walking\"]\n",
    "    steps_ids = [(seq_id + \"_\" + str(i)) for i in range(preds.shape[0])]\n",
    "    res_df = pd.DataFrame(data=preds, columns=CLASSES, index=steps_ids)\n",
    "    return res_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "MODELS_FOLDER = \"models\"\n",
    "model_id = \"best_model\"  # can be changed to \"simplified_model\"\n",
    "model_path = os.path.join(MODELS_FOLDER, model_id, \"model.pth\")\n",
    "params_path = os.path.join(MODELS_FOLDER, model_id, \"params.json\")\n",
    "with open(params_path, \"r\", encoding=\"utf-8\") as f:\n",
    "    PARAMS = json.load(f)\n",
    "\n",
    "model = MultiResidualBiGRU(\n",
    "    PARAMS[\"ISIZE\"],\n",
    "    PARAMS[\"HSIZE\"],\n",
    "    PARAMS[\"NC\"],\n",
    "    PARAMS[\"NL\"],\n",
    ")\n",
    "\n",
    "model = model.to(device)\n",
    "model.load_state_dict(torch.load(model_path))\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "TEST_ROOT_PATH = os.path.join(BASE_FOLDER, \"test\")\n",
    "defog_TEST_PATH = os.path.join(TEST_ROOT_PATH, \"defog\")\n",
    "tDCS_TEST_PATH = os.path.join(TEST_ROOT_PATH, \"tdcsfog\")\n",
    "\n",
    "defog_test_fpaths = glob.glob(os.path.join(defog_TEST_PATH, \"**\"))\n",
    "tdcs_test_fpaths = glob.glob(os.path.join(tDCS_TEST_PATH, \"**\"))\n",
    "\n",
    "SUB_PATH = os.path.join(BASE_FOLDER, \"sample_submission.csv\")\n",
    "sub_df = pd.read_csv(SUB_PATH)\n",
    "\n",
    "# Id column temporarily becomes the explicit pandas index\n",
    "sub_df.set_index(\"Id\", inplace=True)\n",
    "\n",
    "with torch.no_grad():\n",
    "    for root_path in [tDCS_TEST_PATH, defog_TEST_PATH]:\n",
    "        fpaths = glob.glob(os.path.join(root_path, \"**\"))\n",
    "        for fpath in fpaths:\n",
    "            # reading the sequence and its id\n",
    "            seq_id, seq = read_seq(fpath)\n",
    "\n",
    "            # preprocessing the sequence\n",
    "            if root_path == defog_TEST_PATH:\n",
    "                seq = preprocess_defog_seq(\n",
    "                    seq, device, down_hz=PARAMS[\"DOWNHZ\"]\n",
    "                )\n",
    "            else:\n",
    "                seq = preprocess_tdcs_seq(seq, device, down_hz=PARAMS[\"DOWNHZ\"])\n",
    "\n",
    "            # using the model to predict labels\n",
    "            preds = predict_lbls_df(model, seq, seq_id)\n",
    "\n",
    "            if root_path == defog_TEST_PATH:\n",
    "                in_hz = 128 if PARAMS[\"DOWNHZ\"] is None else PARAMS[\"DOWNHZ\"]\n",
    "                preds = resample_seq(preds, in_hz, 100)\n",
    "            elif PARAMS[\"DOWNHZ\"] is not None:  # tdcs\n",
    "                preds = resample_seq(preds, PARAMS[\"DOWNHZ\"], 128)\n",
    "\n",
    "            res_df = build_res_df(preds)\n",
    "\n",
    "            # updating the submission dataframe with these partial results\n",
    "            sub_df.update(res_df)\n",
    "\n",
    "# making Id back to a column and saving the dataframe in a csv file\n",
    "sub_df.reset_index(inplace=True)\n",
    "sub_df.to_csv(\"submission.csv\", index=False)\n",
    "\n",
    "display(sub_df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
